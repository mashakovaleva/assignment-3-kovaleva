{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65a7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ruwordnet.ruwordnet_reader import RuWordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9859c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 29296 edges: 39110\n"
     ]
    }
   ],
   "source": [
    "def build_graph(ruwordnet, pos=\"N\", directed=False):\n",
    "    G = nx.DiGraph() if directed else nx.Graph()\n",
    "\n",
    "    synsets = ruwordnet.get_all_synsets(pos)  # likely list of tuples (id, name)\n",
    "    for row in synsets:\n",
    "        synset_id = row[0] if isinstance(row, tuple) else row  # support both formats\n",
    "        G.add_node(synset_id)\n",
    "\n",
    "        hypers = ruwordnet.get_hypernyms_by_id(synset_id)  # list of synset IDs\n",
    "        for h_id in hypers:\n",
    "            G.add_edge(synset_id, h_id)\n",
    "\n",
    "    return G\n",
    "\n",
    "ruwordnet = RuWordnet(db_path=\"../data/ruwordnet.db\", ruwordnet_path=None)\n",
    "G = build_graph(ruwordnet, pos=\"N\", directed=False) \n",
    "print(\"nodes:\", G.number_of_nodes(), \"edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d00574b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 29296/29296 [00:05<00:00, 5216.84it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [00:09<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "node2vec = Node2Vec(G, dimensions=300, walk_length=20, num_walks=3, workers=1)\n",
    "node2vec_model = node2vec.fit(window=10, min_count=1, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e79fdd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving just in case...\n"
     ]
    }
   ],
   "source": [
    "print('Saving just in case...')\n",
    "node2vec_model.wv.save_word2vec_format(\"models/vectors/node2vec/node2vec_ru_nouns_new.txt\")\n",
    "node2vec_model.save(\"models/node2vec_en_nouns_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "588426f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_model = KeyedVectors.load_word2vec_format(\"models/vectors/node2vec/node2vec_ru_nouns_new.txt\", binary=False)\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(\"models/vectors/fasttext/ruwordnet_nouns_fasttext.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "303b2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 18352/130417 [03:23<20:42, 90.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "is_sense = any(\n",
    "    synset_id == ruwordnet.get_id_by_name('ПОСЕТИТЕЛЬ')\n",
    "    for sense_id, synset_id, text in tqdm(ruwordnet.get_all_senses())\n",
    ")\n",
    "print(is_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797d75cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/29296 [00:00<03:15, 149.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "is_synset = any(\n",
    "    synset_id == ruwordnet.get_id_by_name('ПОСЕТИТЕЛЬ')\n",
    "    for synset_id, text in tqdm(ruwordnet.get_all_synsets('N'))\n",
    ")\n",
    "print(is_synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9763bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04510555 -0.02949081 -0.01271916  0.00454717  0.03544347]\n"
     ]
    }
   ],
   "source": [
    "vector = word2vec_model[f'{ruwordnet.get_id_by_name(\"ПОСЕТИТЕЛЬ\")}']\n",
    "print(vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5570e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: ПОСЕТИТЕЛЬ\n",
      "Query's hypernyms: ЧЕЛОВЕК\n",
      "----------\n",
      "Most similar words (node2vec):\n",
      "ЧИТАТЕЛЬ БИБЛИОТЕКИ 0.9824718832969666 ПОСЕТИТЕЛЬ\n",
      "ЗАВСЕГДАТАЙ 0.9758737087249756 ПОСЕТИТЕЛЬ\n",
      "РЕСПОНДЕНТ 0.9270171523094177 ЧЕЛОВЕК\n",
      "ТОЛСТЯК 0.9252837300300598 ЧЕЛОВЕК\n",
      "СПОРТИВНЫЙ АРБИТР 0.9185411930084229 ЧЕЛОВЕК\n",
      "СВИДЕТЕЛЬ (ЛИЦО, ПРИСУТСТВУЮЩЕЕ ДЛЯ УДОСТОВЕРЕНИЯ) 0.9158520102500916 ОЧЕВИДЕЦ\n",
      "СДАТЧИК (ЛИЦО, ПРОИЗВ. СДАЧУ ПРОДУКЦИИ, ИМУЩ-ВА) 0.915824830532074 ЧЕЛОВЕК\n",
      "ПОДРАЖАТЕЛЬ 0.9141154885292053 ЧЕЛОВЕК\n",
      "ИНТЕЛЛИГЕНТ 0.9134445786476135 ЧЕЛОВЕК\n",
      "МЕДВЕДЬ, СЛОН (НЕУКЛЮЖИЙ ЧЕЛОВЕК) 0.9120302200317383 НЕУКЛЮЖИЙ ЧЕЛОВЕК\n",
      "----------\n",
      "ОБСЛУЖИВАНИЕ ПОСЕТИТЕЛЕЙ 0.6754873991012573 ОБСЛУЖИТЬ (УДОВЛЕТВОРИТЬ НУЖДЫ)\n",
      "ГОСТЬ (ПОСТОРОННЕЕ ЛИЦО) 0.6593257188796997 ПОСТОРОННЕЕ ЛИЦО\n",
      "ГОСТЬ (ТОТ, КТО ПОСЕЩАЕТ, НАВЕЩАЕТ) 0.6593257188796997 ЧЕЛОВЕК ПО РОЛИ\n",
      "НЕЗНАКОМЕЦ 0.651034414768219 ПОСТОРОННЕЕ ЛИЦО\n",
      "ЧИТАТЕЛЬ БИБЛИОТЕКИ 0.6327954530715942 ПОСЕТИТЕЛЬ\n",
      "ПОСТОЯЛЕЦ 0.6144022345542908 ЖИТЕЛЬ\n",
      "КЛИЕНТ, ПОТРЕБИТЕЛЬ УСЛУГ 0.5967244505882263 ПОТРЕБИТЕЛЬ\n",
      "ЭКСКУРСАНТ 0.5926216244697571 ПУТЕШЕСТВЕННИК\n",
      "РАБОТНИК 0.5893873572349548 ЧЕЛОВЕК\n",
      "ПОКУПАТЕЛЬ 0.5887495279312134 СУБЪЕКТ ДЕЯТЕЛЬНОСТИ\n"
     ]
    }
   ],
   "source": [
    "def print_synset_summary(wn, query_name):\n",
    "    print(f\"Synset: {query_name}\",)\n",
    "    query_id = wn.get_id_by_name(query_name)\n",
    "    hypernym_ids = wn.get_hypernyms_by_id(query_id)\n",
    "    for hypernym_id in hypernym_ids:\n",
    "        hypernym_name = wn.get_name_by_id(hypernym_id)\n",
    "        print(f\"Query's hypernyms: {hypernym_name}\")\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print_synset_summary(wn=ruwordnet, query_name='ПОСЕТИТЕЛЬ')\n",
    "print(\"Most similar words (node2vec):\")\n",
    "for synset_id, similarity in node2vec_model.most_similar(ruwordnet.get_id_by_name('ПОСЕТИТЕЛЬ'), topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     print(synset_name, similarity, ruwordnet.get_name_by_id(ruwordnet.get_hypernyms_by_id(synset_id)[0]))\n",
    "print(\"-\"*10)\n",
    "for synset_id, similarity in word2vec_model.most_similar(ruwordnet.get_id_by_name('ПОСЕТИТЕЛЬ'), topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     print(synset_name, similarity, ruwordnet.get_name_by_id(ruwordnet.get_hypernyms_by_id(synset_id)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e08ed378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОБСЛУЖИТЬ (УДОВЛЕТВОРИТЬ НУЖДЫ)\n",
      "ПОСТОРОННЕЕ ЛИЦО\n",
      "ЧЕЛОВЕК ПО РОЛИ\n",
      "ПОСТОРОННЕЕ ЛИЦО\n",
      "ЧЕЛОВЕК\n",
      "ПОСЕТИТЕЛЬ\n",
      "ЖИТЕЛЬ\n",
      "ПОТРЕБИТЕЛЬ\n",
      "ПУТЕШЕСТВЕННИК\n",
      "ЧЕЛОВЕК ПО РОЛИ\n"
     ]
    }
   ],
   "source": [
    "hyper_ids = []\n",
    "for synset_id, similarity in word2vec_model.most_similar(ruwordnet.get_id_by_name('ПОСЕТИТЕЛЬ'), topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     for hyper_id in ruwordnet.get_hypernyms_by_id(synset_id):\n",
    "          hyper_ids.append(hyper_id)\n",
    "for hyper_id in hyper_ids[:10]:\n",
    "    print(ruwordnet.get_name_by_id(hyper_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1448d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПОСЕТИТЕЛЬ\n",
      "ПОСЕТИТЕЛЬ\n",
      "ЧЕЛОВЕК\n",
      "ЧЕЛОВЕК\n",
      "ЧЕЛОВЕК\n",
      "ОЧЕВИДЕЦ\n",
      "ЧЕЛОВЕК\n",
      "ЧЕЛОВЕК\n",
      "ЧЕЛОВЕК\n",
      "НЕУКЛЮЖИЙ ЧЕЛОВЕК\n"
     ]
    }
   ],
   "source": [
    "hyper_ids = []\n",
    "for synset_id, similarity in node2vec_model.most_similar(ruwordnet.get_id_by_name('ПОСЕТИТЕЛЬ'), topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     for hyper_id in ruwordnet.get_hypernyms_by_id(synset_id):\n",
    "          hyper_ids.append(hyper_id)\n",
    "for hyper_id in hyper_ids[:10]:\n",
    "    print(ruwordnet.get_name_by_id(hyper_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4066ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(a, axis=-1, order=2):\n",
    "    \"\"\"Utility function to normalize the rows of a numpy array.\"\"\"\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis)) # (N,)\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "def make_training_matrices(source_dictionary, target_dictionary):\n",
    "    \"\"\"\n",
    "    Source and target dictionaries are the FastVector objects of\n",
    "    source/target languages. bilingual_dictionary is a list of\n",
    "    translation pair tuples [(source_word, target_word), ...].\n",
    "    \"\"\"\n",
    "    source_matrix = []\n",
    "    target_matrix = []\n",
    "\n",
    "    for id, name in ruwordnet.get_all_synsets('N'):\n",
    "        if ' ' not in name:\n",
    "            word_embedding = source_dictionary[id]\n",
    "            node_embedding = target_dictionary[id]\n",
    "            source_matrix.append(word_embedding)\n",
    "            target_matrix.append(node_embedding )\n",
    "    return np.array(source_matrix), np.array(target_matrix)\n",
    "\n",
    "def learn_transformation(source_matrix, target_matrix, normalize_vectors=True):\n",
    "    \"\"\"\n",
    "    Source and target matrices are numpy arrays, shape\n",
    "    (dictionary_length, embedding_dimension). These contain paired\n",
    "    word vectors from the bilingual dictionary.\n",
    "    \"\"\"\n",
    "    if normalize_vectors:\n",
    "        source_matrix = normalized(source_matrix)\n",
    "        target_matrix = normalized(target_matrix)\n",
    "\n",
    "    product = np.matmul(source_matrix.transpose(), target_matrix)\n",
    "    U, s, Vt = np.linalg.svd(product)\n",
    "    return np.matmul(U, Vt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90838342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10173, 300) (10173, 300)\n"
     ]
    }
   ],
   "source": [
    "src_matrix, trg_matrix = make_training_matrices(word2vec_model, node2vec_model)\n",
    "transform = learn_transformation(src_matrix, trg_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ecace1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ДОХОД\n",
      "ЕДА, ПИЩА\n",
      "ЕДА, ПИЩА\n",
      "РАСТИТЕЛЬНЫЕ КОРМА\n",
      "СИЛОС\n",
      "ПРЕДМЕТ, ВЕЩЬ\n",
      "ПЕРСОНАЖ\n",
      "РАСТИТЕЛЬНЫЕ КОРМА\n",
      "ПРИПРАВА\n",
      "ПИЩЕВКУСОВЫЕ ПРОДУКТЫ\n"
     ]
    }
   ],
   "source": [
    "vector = word2vec_model[f'{ruwordnet.get_id_by_name(\"ПОСЕТИТЕЛЬ\")}']\n",
    "hyper_ids = []\n",
    "for synset_id, similarity in node2vec_model.similar_by_vector(vector, topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     for hyper_id in ruwordnet.get_hypernyms_by_id(synset_id):\n",
    "          hyper_ids.append(hyper_id)\n",
    "for hyper_id in hyper_ids[:10]:\n",
    "    print(ruwordnet.get_name_by_id(hyper_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e074234d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПЕРЕСЕЛЕНЕЦ\n",
      "ПОМОЩНИК (ЧЕЛОВЕК)\n",
      "СПАСАТЕЛЬ\n",
      "ПОМОЩНИК (ЧЕЛОВЕК)\n",
      "УЧЕНИК (НАЧИНАЮЩИЙ РАБОТНИК)\n",
      "ПОМОЩНИК (ЧЕЛОВЕК)\n",
      "РАБОТНИК\n",
      "ПЕРЕСЕЛЕНЕЦ\n",
      "ПОСОБНИК ПРЕСТУПЛЕНИЯ\n",
      "СПАСИТЕЛЬ, СПАСИТЕЛЬНИЦА\n"
     ]
    }
   ],
   "source": [
    "hyper_ids = []\n",
    "for synset_id, similarity in node2vec_model.similar_by_vector(vector @ transform, topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     for hyper_id in ruwordnet.get_hypernyms_by_id(synset_id):\n",
    "          hyper_ids.append(hyper_id)\n",
    "for hyper_id in hyper_ids[:10]:\n",
    "    print(ruwordnet.get_name_by_id(hyper_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd5741e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "БЕЖЕНЕЦ 0.622832179069519 ПЕРЕСЕЛЕНЕЦ\n",
      "ПОВОДЫРЬ СЛЕПОГО 0.6207084059715271 ПОМОЩНИК (ЧЕЛОВЕК)\n",
      "ГОРНОСПАСАТЕЛЬ 0.6138981580734253 СПАСАТЕЛЬ\n",
      "ПОДМАСТЕРЬЕ 0.6108173131942749 ПОМОЩНИК (ЧЕЛОВЕК)\n",
      "АССИСТЕНТ (ПОМОЩНИК) 0.6095923185348511 ПОМОЩНИК (ЧЕЛОВЕК)\n",
      "ИММИГРАНТ 0.6052301526069641 ПЕРЕСЕЛЕНЕЦ\n",
      "НАВОДЧИК (ПОСОБНИК ПРЕСТУПЛЕНИЯ) 0.6049227714538574 ПОСОБНИК ПРЕСТУПЛЕНИЯ\n",
      "СПАСАТЕЛЬ 0.6035510301589966 СПАСИТЕЛЬ, СПАСИТЕЛЬНИЦА\n",
      "СВАХА 0.6016280055046082 ЧЕЛОВЕК ПО СФЕРЕ ДЕЯТЕЛЬНОСТИ\n",
      "ЧУЖАК, ПРИШЛЫЙ ЧЕЛОВЕК 0.6005294919013977 ПОСТОРОННЕЕ ЛИЦО\n"
     ]
    }
   ],
   "source": [
    "for synset_id, similarity in node2vec_model.similar_by_vector(vector @ transform, topn=10):\n",
    "     synset_name = ruwordnet.get_name_by_id(synset_id)\n",
    "     print(synset_name, similarity, ruwordnet.get_name_by_id(ruwordnet.get_hypernyms_by_id(synset_id)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "933f3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform_to_dict(emb_dict, transform):\n",
    "    \"\"\"\n",
    "    emb_dict: dict[token] -> np.array(d,)\n",
    "    transform: np.array(d, d)\n",
    "    returns: new dict[token] -> np.array(d,)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for key, vec in emb_dict.items():\n",
    "        out[key] = vec @ transform   # (d,) @ (d,d) -> (d,)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
